"use strict";(self.webpackChunkbacalhau_docs=self.webpackChunkbacalhau_docs||[]).push([[5846],{3905:(e,t,o)=>{o.d(t,{Zo:()=>c,kt:()=>p});var a=o(7294);function n(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function r(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,a)}return o}function i(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?r(Object(o),!0).forEach((function(t){n(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):r(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function s(e,t){if(null==e)return{};var o,a,n=function(e,t){if(null==e)return{};var o,a,n={},r=Object.keys(e);for(a=0;a<r.length;a++)o=r[a],t.indexOf(o)>=0||(n[o]=e[o]);return n}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)o=r[a],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(n[o]=e[o])}return n}var l=a.createContext({}),u=function(e){var t=a.useContext(l),o=t;return e&&(o="function"==typeof e?e(t):i(i({},t),e)),o},c=function(e){var t=u(e.components);return a.createElement(l.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var o=e.components,n=e.mdxType,r=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=u(o),p=n,b=d["".concat(l,".").concat(p)]||d[p]||h[p]||r;return o?a.createElement(b,i(i({ref:t},c),{},{components:o})):a.createElement(b,i({ref:t},c))}));function p(e,t){var o=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var r=o.length,i=new Array(r);i[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:n,i[1]=s;for(var u=2;u<r;u++)i[u]=o[u];return a.createElement.apply(null,i)}return a.createElement.apply(null,o)}d.displayName="MDXCreateElement"},4827:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>u});var a=o(3117),n=(o(7294),o(3905));const r={sidebar_label:"Architecture",sidebar_position:2},i="Architecture",s={unversionedId:"about-bacalhau/architecture",id:"about-bacalhau/architecture",title:"Architecture",description:"Purpose",source:"@site/docs/about-bacalhau/architecture.md",sourceDirName:"about-bacalhau",slug:"/about-bacalhau/architecture",permalink:"/about-bacalhau/architecture",draft:!1,editUrl:"https://github.com/bacalhau-project/docs.bacalhau.org/blob/main/docs/about-bacalhau/architecture.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_label:"Architecture",sidebar_position:2},sidebar:"documentationSidebar",previous:{title:"Introduction",permalink:"/about-bacalhau/introduction"},next:{title:"Landscape",permalink:"/about-bacalhau/compute-landscape"}},l={},u=[{value:"Purpose",id:"purpose",level:2},{value:"System Components",id:"system-components",level:2},{value:"Transport (interface)",id:"transport-interface",level:3},{value:"Requester node (component)",id:"requester-node-component",level:3},{value:"Compute node (component)",id:"compute-node-component",level:3},{value:"Executor (interface)",id:"executor-interface",level:3},{value:"Storage Provider (interface)",id:"storage-provider-interface",level:3},{value:"Verifier (interface)",id:"verifier-interface",level:3},{value:"Job Lifecycle",id:"job-lifecycle",level:2},{value:"Job Submission",id:"job-submission",level:3},{value:"Job Acceptance",id:"job-acceptance",level:3},{value:"Job Execution",id:"job-execution",level:3},{value:"Job Completion",id:"job-completion",level:3},{value:"Input / Output Volumes",id:"input--output-volumes",level:3},{value:"Networking",id:"networking",level:3}],c={toc:u};function h(e){let{components:t,...r}=e;return(0,n.kt)("wrapper",(0,a.Z)({},c,r,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"architecture"},"Architecture"),(0,n.kt)("h2",{id:"purpose"},"Purpose"),(0,n.kt)("p",null,'The purpose of Bacalhau is to provide a platform for public, transparent, and optionally verifiable computation. Bacalhau enables users to run arbitrary docker containers and wasm images as tasks against data stored in IPFS. This architecture is also referred to as Compute Over Data (or CoD). The Portuguese word for salted Cod fish is "Bacalhau" which is the origin of the project\'s name.'),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"image",src:o(9191).Z,width:"1152",height:"864"})),(0,n.kt)("p",null,"Bacalhau operates as a peer-to-peer network of nodes where each node has both a requestor and compute component.  To interact with the cluster - Bacalhau CLI requests are sent to a node in the cluster (via JSON over HTTP), which then broadcasts messages over the transport layer to other nodes in the cluster.  All other nodes in the network are connected to the transport layer and as such have a shared view of the world."),(0,n.kt)("h2",{id:"system-components"},"System Components"),(0,n.kt)("p",null,"Bacalhau's architecture is divided among the following core components and interfaces: "),(0,n.kt)("h3",{id:"transport-interface"},"Transport (interface)"),(0,n.kt)("p",null,"The transport component is responsible for connecting different bacalhau nodes in the peer to peer network. Its job is to broadcast messages about jobs as they are created, bid upon and executed by compute nodes."),(0,n.kt)("p",null,"As well as handling the distribution of messages to other nodes, It\u2019s also responsible for handling the \u201cidentity\u201d of an individual bacalhau node."),(0,n.kt)("p",null,"The main implementation of the transport interface in a production Bacalhau network is the libp2p transport.  This uses the GossipSub handler to distribute job messages to other nodes on the network."),(0,n.kt)("h3",{id:"requester-node-component"},"Requester node (component)"),(0,n.kt)("p",null,"The requestor node is responsible for handling requests from clients using JSON over HTTP and is the main \u201ccustodian\u201d of jobs submitted to it."),(0,n.kt)("p",null,"When you submit a job to a given Requestor node - it handles the process of broadcasting that job to the network and then accepting or rejecting the various bids that will come back in for that job.  There is only ever a single requestor node for a given job and that is the requestor node that job was originally submitted to."),(0,n.kt)("h3",{id:"compute-node-component"},"Compute node (component)"),(0,n.kt)("p",null,"When a new job is seen on the network - the Compute node will decide whether it wants to \u201cbid\u201d on that job or not.  If a bid is made and subsequently accepted by the requester node - a \u201cbid accepted\u201d event will then trigger the Compute node to \u201crun\u201d the job using its collection of \u201cexecutors\u201d (each of which in turn has a collection of \u201cstorage providers\u201d)."),(0,n.kt)("p",null,"Once the executor has run the job and has produced some results - the Compute node will then pass those results off to the \u201cverifier\u201d to process them.  The Compute node has a collection of named verifiers and will pick the most appropriate one based on the job spec."),(0,n.kt)("h3",{id:"executor-interface"},"Executor (interface)"),(0,n.kt)("p",null,"The Executor is what actually \u201cruns\u201d the job and checks for the locality of storage used by a job.   It will handle \u201cpresenting\u201d the input and output storage volumes into the job when it is run."),(0,n.kt)("p",null,"Storage means something entirely different between something like docker and WASM and so if a job mentions \u201cuse this IPFS cid\u201d - it will result in two different storage providers being used depending on if the job is using the docker or WASM executor."),(0,n.kt)("p",null,"Put another way - the executor has two main jobs:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Present the storage volumes in a way that is appropriate for the executor"),(0,n.kt)("li",{parentName:"ul"},"Run the job")),(0,n.kt)("p",null,"When it\u2019s finished running the job (and there was not an error in the job), the executor should result in a local folder containing the results of the job."),(0,n.kt)("p",null,"The idea is that Bacalhau makes it really easy to write new executors and it grows into a polyglot network of different compute implementations."),(0,n.kt)("h3",{id:"storage-provider-interface"},"Storage Provider (interface)"),(0,n.kt)("p",null,"Storage providers are responsible for presenting some upstream storage source (e.g. ipfs cid) into an executor in an opinionated way."),(0,n.kt)("p",null,"For example - we might have the following two storage providers:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"IPFS posix - a storage provider that manifests a CID as a POSIX filesystem"),(0,n.kt)("li",{parentName:"ul"},"IPFS library - a storage provider that streams the contents of a CID via a library call")),(0,n.kt)("p",null,"And we might have the following two executor implementations:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Docker - run docker containers"),(0,n.kt)("li",{parentName:"ul"},"WASM - run WASM binaries")),(0,n.kt)("p",null,"If we submit a job with a volume of type \u201cipfs\u201d to both executors - it should result in the docker executor using the \u201cIPFS posix\u201d storage provider and the WASM executor using the \u201cIPFS library\u201d provider."),(0,n.kt)("p",null,"As such - an executor implementation will \u201ccontain\u201d the storage providers it can operate with and they are loosely coupled (the IPFS posix/library storage providers can be used across multiple executors where appropriate)."),(0,n.kt)("h3",{id:"verifier-interface"},"Verifier (interface)"),(0,n.kt)("p",null,"The verifier takes over once the executor has run the job.  Its main two tasks is to check the results produced by the executor (against results produced by other nodes) and to transport those results back to the client somehow."),(0,n.kt)("p",null,"How the results are checked depend on the nature of the job.  For example - if the job is deterministic - the \u201ccheck the hash of the results are the same\u201d verifier can be used but if the job is non-deterministic, another approach must be used."),(0,n.kt)("p",null,"The job will state which verifier to use and there are currently the following verifier implementations:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},'noop - does nothing and just returns the local folder given to it as the "results" (useful for tests)'),(0,n.kt)("li",{parentName:"ul"},"ipfs - publishes the results to ipfs so the client / requester can download the files produced by the job\nNote: currently neither of these verifiers actually perform any verification. They are concerned only with transporting the results. However, this will be used when the WASM executor is introduced in a future release.")),(0,n.kt)("h2",{id:"job-lifecycle"},"Job Lifecycle"),(0,n.kt)("h3",{id:"job-submission"},"Job Submission"),(0,n.kt)("p",null,"Jobs submitted via the Bacalhau CLI are forwarded to a bacalhau cluster node at bootstrap.production.bacalhau.org via port 1234 by default. This bacalhau node will act as the \u201crequestor node\u201d for the duration of the job lifecycle."),(0,n.kt)("p",null,"When jobs are submitted to the requestor node - all compute nodes hear of this new job and can choose to \u201cbid\u201d on it.  The job deal will have a \u201cconcurrency\u201d setting which means \u201chow many different nodes I want to run this job\u201d.  The job might also mention the use of \u201cvolumes\u201d (for example some IPFS CIDs).  The compute node can choose to bid on the job if the data for the volumes resides locally to the compute node or it can choose to bid anyway.  Bacalhau will support the use of external http or exec hooks to decide if a node wants to bid on a job.  This means a node operator can give fine grained rules as to what jobs they are willing to run."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"image",src:o(9363).Z,width:"1152",height:"864"})),(0,n.kt)("h3",{id:"job-acceptance"},"Job Acceptance"),(0,n.kt)("p",null,"As these bids from compute nodes arrive back at the originating requester node - it can choose which bids to accept and which ones to reject.  This can be based on the previous reputation of each compute node or any other factors the requestor node might take into account (like locality, hardware resources, cost etc).  The requestor node will also have the same http or exec hooks to decide if it wants to accept a bid from a given compute node.  This means a node operator can give fine grained rules as to what jbids they are willing to accept."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"image",src:o(2131).Z,width:"1152",height:"864"})),(0,n.kt)("h3",{id:"job-execution"},"Job Execution"),(0,n.kt)("p",null,"As accepted bids are received by compute nodes - they will \u201cexecute\u201d the job using the executor for that job and the storage providers that executor provides for that job."),(0,n.kt)("p",null,"For example - a job could use the \u201cdocker\u201d executor and \u201cipfs\u201d storage volumes.  This would result in a POSIX mount of the IPFS storage into a running container.  Alternatively - a job could use the \u201cWASM\u201d executor and \u201cipfs\u201d storage volumes.  This would result in a WASM style syscall to stream the storage bytes into the WASM runtime.  The point is that each \u201cexecutor\u201d will deal with storage in a different way and so even though each job mentions \u201cipfs\u201d storage volumes - they would both end up with different implementations at runtime."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"image",src:o(9771).Z,width:"1152",height:"864"})),(0,n.kt)("h3",{id:"job-completion"},"Job Completion"),(0,n.kt)("p",null,"Once the executor has completed the running of the job - its results are then passed to the \u201cverifier\u201d.  Its task is to decide how to validate and return the results back to the client.  Again - this depends on the nature of the job.  If the nature of the job is deterministic - then the \u201coutput hash\u201d verifier can be used (where all hashes of the outputs from all compute nodes must match).  Whereas if the job is non-deterministic, another style of verifier might be used (or none at all!)"),(0,n.kt)("p",null,"The outcome of this lifecycle is that a requestor node is able to list the results of a job to the original client that requested it."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"image",src:o(1422).Z,width:"1152",height:"864"})),(0,n.kt)("h3",{id:"input--output-volumes"},"Input / Output Volumes"),(0,n.kt)("p",null,"A job includes the concept of input and output volumes and the docker executor implements support for these. This means you can specific ipfs CIDs and input paths and also write results to an output volume - this can be seen by the following example:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"cid=$(ipfs add file.txt)\nbacalhau docker run \\\n  -v $cid:/file.txt \\\n  -o apples:/output_folder \\\n  ubuntu \\\n  bash -c 'cat /file.txt > /output_folder/file.txt'\n")),(0,n.kt)("p",null,"The above example demonstrates an input volume flag \u201c-v $cid:/file.txt\u201d, which mounts the contents of $cid within the docker container at location /file.txt (root)."),(0,n.kt)("p",null,"Output volumes are mounted to the docker container at the location specified. In the example above, any content written to /output_folder will be made available within the apples folder in the job results CID."),(0,n.kt)("p",null,"Once the job has run on the executor - the contents of stdout and stderr will be added to any named output volumes the job has used (in this case apples) and all those entities will be packaged into the results folder which is then published to ipfs via the verifier."),(0,n.kt)("h3",{id:"networking"},"Networking"),(0,n.kt)("p",null,"Jobs should only require dependencies that are baked into their Docker images and the input files mounted from IPFS in order to produce their output, therefore egress access to the network is currently disabled."))}h.isMDXComponent=!0},2131:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/architecture-bid-accept-c541f3a23a90c2cfb07b47d401b202ca.jpeg"},9363:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/architecture-bid-submission-7c64a8dd1e973cf99d718cb59cc2d2b0.jpeg"},1422:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/architecture-complete-a2d6d59ee201bd392368fa1f52875aad.jpeg"},9771:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/architecture-execute-2bac1c0560e5a8804b88b118ac04f1f2.jpeg"},9191:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/architecture1-610652254b08aa3cf9fe060eab9ec2cb.jpeg"}}]);