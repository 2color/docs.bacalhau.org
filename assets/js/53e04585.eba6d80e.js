"use strict";(self.webpackChunkbacalhau_docs=self.webpackChunkbacalhau_docs||[]).push([[7125],{6699:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>u,contentTitle:()=>r,default:()=>d,frontMatter:()=>i,metadata:()=>l,toc:()=>s});var o=a(7462),n=(a(7294),a(3905));a(2004);const i={sidebar_label:"Onboard Your Workload",sidebar_position:2},r="Onboarding Your Workloads",l={unversionedId:"getting-started/workload-onboarding",id:"getting-started/workload-onboarding",title:"Onboarding Your Workloads",description:"This tutorial describes how to convert your workload into a Bacalhau format. To migrate your workload, follow the instructions below for the job format you want to use. Check out the examples for more inspiration on this process.",source:"@site/docs/getting-started/workload-onboarding.md",sourceDirName:"getting-started",slug:"/getting-started/workload-onboarding",permalink:"/getting-started/workload-onboarding",draft:!1,editUrl:"https://github.com/bacalhau-project/docs.bacalhau.org/blob/main/docs/getting-started/workload-onboarding.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_label:"Onboard Your Workload",sidebar_position:2},sidebar:"documentationSidebar",previous:{title:"Installation",permalink:"/getting-started/installation"},next:{title:"Specifying Hardware Requirements",permalink:"/getting-started/resources"}},u={},s=[{value:"Docker",id:"docker",level:2},{value:"Prerequisites and Limitations",id:"prerequisites-and-limitations",level:3},{value:"Onboarding",id:"onboarding",level:3},{value:"Step 1 - (Optional) Read Data From the <code>/inputs</code> Directory",id:"step-1---optional-read-data-from-the-inputs-directory",level:4},{value:"Step 2 - (Optional) Write Data to the <code>/outputs</code> Directory",id:"step-2---optional-write-data-to-the-outputs-directory",level:4},{value:"Step 3 - (Optional) Build and Push Your Image To a Public Registry",id:"step-3---optional-build-and-push-your-image-to-a-public-registry",level:4},{value:"Step 4 - Test Your Container",id:"step-4---test-your-container",level:4},{value:"Step 5 - (Optional) Upload the Input Data to IPFS",id:"step-5---optional-upload-the-input-data-to-ipfs",level:4},{value:"Step 6 - Run the Workload on Bacalhau",id:"step-6---run-the-workload-on-bacalhau",level:4},{value:"Examples",id:"examples",level:3},{value:"Support",id:"support",level:2}],p={toc:s};function d(e){let{components:t,...a}=e;return(0,n.kt)("wrapper",(0,o.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"onboarding-your-workloads"},"Onboarding Your Workloads"),(0,n.kt)("p",null,"This tutorial describes how to convert your workload into a Bacalhau format. To migrate your workload, follow the instructions below for the job format you want to use. Check out the examples for more inspiration on this process."),(0,n.kt)("admonition",{type:"tip"},(0,n.kt)("p",{parentName:"admonition"},"We will be adding more job formats soon!")),(0,n.kt)("h2",{id:"docker"},"Docker"),(0,n.kt)("p",null,"Here you'll learn how to migrate a workload based on a Docker container into a format that will work with the Bacalhau client."),(0,n.kt)("h3",{id:"prerequisites-and-limitations"},"Prerequisites and Limitations"),(0,n.kt)("p",null,"To help provide a safe, secure network for all users, we add the following runtime restrictions:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"All ingress/egress networking is disabled. You won't be able to pull data/code/weights/etc. from an external source."),(0,n.kt)("li",{parentName:"ul"},"Data passing is implemented with Docker volumes, using ",(0,n.kt)("a",{parentName:"li",href:"/about-bacalhau/architecture#input--output-volumes"},"Bacalhau's input/output volumes"),".")),(0,n.kt)("p",null,"The following lists current limitations:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Public container registries only"),(0,n.kt)("li",{parentName:"ul"},"Containers must have an ",(0,n.kt)("inlineCode",{parentName:"li"},"x86_64")," CPU architecture"),(0,n.kt)("li",{parentName:"ul"},"The ",(0,n.kt)("inlineCode",{parentName:"li"},"--inputs")," and ",(0,n.kt)("inlineCode",{parentName:"li"},"--input-volumes")," flags do not support CID subpaths. Directories only."),(0,n.kt)("li",{parentName:"ul"},"The ",(0,n.kt)("inlineCode",{parentName:"li"},"--input-urls")," flag does not support URL directories. Single files only.")),(0,n.kt)("h3",{id:"onboarding"},"Onboarding"),(0,n.kt)("h4",{id:"step-1---optional-read-data-from-the-inputs-directory"},"Step 1 - (Optional) Read Data From the ",(0,n.kt)("inlineCode",{parentName:"h4"},"/inputs")," Directory"),(0,n.kt)("p",null,"If you need to pass data into your container you will do this via a Docker volume, so you'll need to modify your code to read from a local directory."),(0,n.kt)("p",null,"We make the assumption that you are reading from a directory called ",(0,n.kt)("inlineCode",{parentName:"p"},"/inputs"),", which is set as the default."),(0,n.kt)("admonition",{type:"tip"},(0,n.kt)("p",{parentName:"admonition"},"You can specify which directory the data is written to with the ",(0,n.kt)("inlineCode",{parentName:"p"},"--input-volumes")," CLI flag.")),(0,n.kt)("h4",{id:"step-2---optional-write-data-to-the-outputs-directory"},"Step 2 - (Optional) Write Data to the ",(0,n.kt)("inlineCode",{parentName:"h4"},"/outputs")," Directory"),(0,n.kt)("p",null,"If you need to return data from your container you will do this via a Docker volume, so you'll need to modify your code to write to a local directory."),(0,n.kt)("p",null,"We make the assumption that you are writing to a directory called ",(0,n.kt)("inlineCode",{parentName:"p"},"/outputs"),", which is set as the default."),(0,n.kt)("admonition",{type:"tip"},(0,n.kt)("p",{parentName:"admonition"},"You can specify which directory the data is written to with the ",(0,n.kt)("inlineCode",{parentName:"p"},"--output-volumes")," CLI flag.")),(0,n.kt)("h4",{id:"step-3---optional-build-and-push-your-image-to-a-public-registry"},"Step 3 - (Optional) Build and Push Your Image To a Public Registry"),(0,n.kt)("p",null,"If you haven't already, ",(0,n.kt)("a",{parentName:"p",href:"https://docs.docker.com/engine/reference/commandline/build/"},"build your image")," and ",(0,n.kt)("a",{parentName:"p",href:"https://docs.docker.com/engine/reference/commandline/push/"},"push it")," to a publicly accessible container registry."),(0,n.kt)("admonition",{type:"caution"},(0,n.kt)("p",{parentName:"admonition"},"All Bacalhau nodes are of an ",(0,n.kt)("inlineCode",{parentName:"p"},"x86_64")," architecture, therefore containers must be built for ",(0,n.kt)("inlineCode",{parentName:"p"},"x86_64")," systems.")),(0,n.kt)("p",null,"For example:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-bash"},"export IMAGE=myuser/myimage:latest\ndocker build -t ${IMAGE} .\ndocker image push ${IMAGE}\n")),(0,n.kt)("h4",{id:"step-4---test-your-container"},"Step 4 - Test Your Container"),(0,n.kt)("p",null,"Execute the following command to test your docker image locally, changing the environment variables as necessary:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-bash"},"export LOCAL_INPUT_DIR=$PWD\nexport LOCAL_OUTPUT_DIR=$PWD\nexport CMD=(sh -c 'ls /inputs; echo do something useful > /outputs/stdout')\ndocker run --rm \\\n  -v ${LOCAL_INPUT_DIR}:/inputs  \\\n  -v ${LOCAL_OUTPUT_DIR}:/outputs \\\n  ${IMAGE} \\\n  ${CMD}\n")),(0,n.kt)("p",null,"For example:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-bash"},"export IMAGE=ubuntu\ndocker run --rm \\\n  -v ${LOCAL_INPUT_DIR}:/inputs  \\\n  -v ${LOCAL_OUTPUT_DIR}:/outputs \\\n  ${IMAGE} \\\n  ${CMD}\ncat stdout\n")),(0,n.kt)("p",null,"This snippet results in:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-bash"},"...file listing...\ndo something useful\n")),(0,n.kt)("h4",{id:"step-5---optional-upload-the-input-data-to-ipfs"},"Step 5 - (Optional) Upload the Input Data to IPFS"),(0,n.kt)("p",null,"We recommend uploading your data to IPFS for persistent storage, because:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Bacalhau is designed to perform the computation next to the data"),(0,n.kt)("li",{parentName:"ul"},"Distributing data across the solar system with IPFS distributes the Bacalhau computation"),(0,n.kt)("li",{parentName:"ul"},"Distributing computation improves performance by scaling, and improves resiliency via redundancy"),(0,n.kt)("li",{parentName:"ul"},"Using IPFS CIDs as inputs enables repeatable and cacheable execution")),(0,n.kt)("admonition",{type:"tip"},(0,n.kt)("p",{parentName:"admonition"},"The following guides explain how to store data on the IPFS network."),(0,n.kt)("ul",{parentName:"admonition"},(0,n.kt)("li",{parentName:"ul"},"Leverage an IPFS \u201cpinning service\u201d such as:",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://web3.storage/account/"},"Web3.Storage")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://estuary.tech/sign-in"},"Estuary")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://docs.ipfs.io/how-to/pin-files/"},"Manually pin your files to IPFS")," with your own IPFS server."))),(0,n.kt)("li",{parentName:"ul"},"If uploading a folder of input files, consider ",(0,n.kt)("a",{parentName:"li",href:"https://web3.storage/docs/#create-the-upload-script"},"uploading with this script"),". However, please note that any content uploaded to Web3.storage is ",(0,n.kt)("a",{parentName:"li",href:"https://web3.storage/docs/how-tos/store/#directory-wrapping"},"also wrapped in a parent directory"),". You will need to take care to reference the inner directory CID in your bacalhau command."))),(0,n.kt)("h4",{id:"step-6---run-the-workload-on-bacalhau"},"Step 6 - Run the Workload on Bacalhau"),(0,n.kt)("p",null,"To run your workload using input data stored in IPFS use the following command:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-bash"},"bacalhau docker run --inputs ${CID} ${IMAGE} ${CMD}\n\nbacalhau list \n\nbacalhau get JOB_ID\n")),(0,n.kt)("p",null,"For example, running:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-bash"},"job_id=$(bacalhau docker run ubuntu echo hello)\nbacalhau list --id-filter $job_id\nsleep 5\nbacalhau list --id-filter $job_id\nbacalhau get $job_id\nls shards\n")),(0,n.kt)("p",null,"results in:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-bash"}," CREATED   ID        JOB                      STATE      VERIFIED  PUBLISHED \n 10:26:00  24440f0d  Docker ubuntu echo h...  Verifying                      \n CREATED   ID        JOB                      STATE      VERIFIED  PUBLISHED               \n 10:26:00  24440f0d  Docker ubuntu echo h...  Published            /ipfs/bafybeiflj3kha... \n11:26:09.107 | INF bacalhau/get.go:67 > Fetching results of job '24440f0d-3c06-46af-9adf-cb524aa43961'...\n11:26:10.528 | INF ipfs/downloader.go:115 > Found 1 result shards, downloading to temporary folder.\n11:26:13.144 | INF ipfs/downloader.go:195 > Combining shard from output volume 'outputs' to final location: '/Users/phil/source/filecoin-project/docs.bacalhau.org'\njob-24440f0d-3c06-46af-9adf-cb524aa43961-shard-0-host-QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3\n")),(0,n.kt)("admonition",{type:"caution"},(0,n.kt)("p",{parentName:"admonition"},"The ",(0,n.kt)("inlineCode",{parentName:"p"},"--inputs")," flag does not support CID subpaths.")),(0,n.kt)("p",null,"Alternatively, you can run your workload with a publicly accessible http(s) URL, which will download the data temporarily into IPFS:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-bash"},"export URL=https://download.geofabrik.de/antarctica-latest.osm.pbf\nbacalhau docker run --input-urls ${URL}:/inputs ${IMAGE} ${CMD}\n\nbacalhau list \n\nbacalhau get JOB_ID\n")),(0,n.kt)("admonition",{type:"caution"},(0,n.kt)("p",{parentName:"admonition"},"The ",(0,n.kt)("inlineCode",{parentName:"p"},"--input-urls")," flag does not support URL directories.")),(0,n.kt)("h3",{id:"examples"},"Examples"),(0,n.kt)("p",null,"Here is an example of an onboarded workload leveraging the Surface Ocean CO\u2082 Atlas (SOCAT) to Bacalhau:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=t2AHD8yJhLY"},"Youtube: Bacalhau SOCAT Workload Demo")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/wesfloyd/bacalhau_socat_test"},"Github: bacalhau_socat_test"))),(0,n.kt)("p",null,"Here is an example of running a job live on the Bacalhau network: ",(0,n.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=wkOh05J5qgA"},"Youtube: Bacalhau Intro Video")),(0,n.kt)("h2",{id:"support"},"Support"),(0,n.kt)("p",null,"Please reach out to the ",(0,n.kt)("a",{parentName:"p",href:"https://filecoinproject.slack.com/archives/C02RLM3JHUY"},"Bacalhau team via Slack")," if you would like help pinning data to IPFS for your job or for any issues you encounter."))}d.isMDXComponent=!0}}]);